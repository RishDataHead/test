I can see the issue clearly! The problem is that chunks are already running when chunk 5 fails, and the cancellation happens too late. Chunks 6 and 7 were already submitted to the thread pool before the failure was detected.The root cause is:All chunks (0-9) are submitted to ThreadPoolExecutor before any failureWhen chunk 5 fails, chunks 6 and 7 are already running in parallelThe failure_event.is_set() check in _load_chunk() happens at the START of execution, not duringFix: Stop Submitting Chunks ImmediatelyHere's the corrected enterprise_data_loader/loaders/data_loader.py - modify the chunk submission logic:Find this section (around line 360-380):        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit first chunk
            logger.info(f"Submitting chunk {chunk_id} to thread pool")
            futures.append(executor.submit(self._load_chunk, first_chunk, chunk_id))
            chunk_id += 1
            
            # Submit remaining chunks
            for chunk in data_generator:
                # In atomic mode, stop submitting if failure occurred
                if self.atomic_load and self.failure_event.is_set():
                    logger.warning(f"Failure detected - stopping chunk submission at chunk {chunk_id}")
                    break
                
                logger.info(f"Submitting chunk {chunk_id} to thread pool ({len(chunk)} rows)")
                futures.append(executor.submit(self._load_chunk, chunk, chunk_id))
                chunk_id += 1Replace with this SEQUENTIAL submission approach:        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # Submit first chunk
            logger.info(f"Submitting chunk {chunk_id} to thread pool")
            future = executor.submit(self._load_chunk, first_chunk, chunk_id)
            futures.append(future)
            chunk_id += 1
            
            # Submit remaining chunks ONE AT A TIME with failure check
            for chunk in data_generator:
                # Wait for previous chunk to complete if atomic mode
                if self.atomic_load:
                    # Check if any previous chunk failed
                    if self.failure_event.is_set():
                        logger.warning(f"Failure detected - stopping chunk submission at chunk {chunk_id}")
                        logger.warning(f"Chunks {chunk_id} onwards will NOT be processed")
                        break
                    
                    # Check recently completed futures for failures
                    for f in list(futures):
                        if f.done():
                            result = f.result()
                            if result.get('rows_failed', 0) > 0:
                                logger.warning(f"Chunk {result['chunk_id']} failed - stopping further submissions")
                                break
                
                logger.info(f"Submitting chunk {chunk_id} to thread pool ({len(chunk)} rows)")
                future = executor.submit(self._load_chunk, chunk, chunk_id)
                futures.append(future)
                chunk_id += 1
                
                # In atomic mode, limit parallel execution to catch failures faster
                if self.atomic_load:
                    # Wait if we have too many running chunks
                    running = sum(1 for f in futures if not f.done())
                    if running >= self.max_workers:
                        # Wait for at least one to complete
                        from concurrent.futures import wait, FIRST_COMPLETED
                        wait(futures, return_when=FIRST_COMPLETED)Also add this import at the top:from concurrent.futures import ThreadPoolExecutor, as_completed, wait, FIRST_COMPLETEDAlternative: Better Solution - Smaller Batches in Atomic ModeReplace the entire chunk submission and collection with this safer approach:        # For atomic mode, process in controlled batches
        if self.atomic_load:
            logger.info("ATOMIC MODE: Processing chunks sequentially to detect failures early")
            
            # Process first chunk
            result = self._load_chunk(first_chunk, chunk_id)
            self._process_result(result)
            chunk_id += 1
            
            if result.get('rows_failed', 0) > 0:
                logger.error(f"First chunk failed - aborting load")
            else:
                # Process remaining chunks
                for chunk in data_generator:
                    # Stop if previous chunk failed
                    if self.failure_event.is_set():
                        logger.warning(f"Stopping at chunk {chunk_id} due to previous failure")
                        break
                    
                    result = self._load_chunk(chunk, chunk_id)
                    self._process_result(result)
                    chunk_id += 1
                    
                    if result.get('rows_failed', 0) > 0:
                        logger.error(f"Chunk {chunk_id-1} failed - aborting load")
                        break
        else:
            # Non-atomic mode: parallel processing as before
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures.append(executor.submit(self._load_chunk, first_chunk, chunk_id))
                chunk_id += 1
                
                for chunk in data_generator:
                    futures.append(executor.submit(self._load_chunk, chunk, chunk_id))
                    chunk_id += 1
                
                for future in as_completed(futures):
                    result = future.result()
                    self._process_result(result)Add this helper method:    def _process_result(self, result: Dict[str, Any]):
        """Process a chunk result and update statistics"""
        with self.stats_lock:
            if not result.get('skipped', False):
                self.total_rows += result.get('rows_inserted', 0)
                self.failed_rows += result.get('rows_failed', 0)
                
                if result.get('rows_failed', 0) > 0:
                    failed_chunk_info = {
                        'chunk_id': result['chunk_id'],
                        'rows_failed': result['rows_failed'],
                        'total_rows': result['total_rows'],
                        'error_message': result.get('error_message', 'Unknown error')
                    }
                    self.failed_chunks.append(failed_chunk_info)Why This WorksSequential in Atomic Mode: Chunks process one-by-one, so failure is detected before next chunk startsImmediate Stop: No chunks are submitted after failure is detectedClean Logs: Logs appear in order (Chunk 0, 1, 2... stops at first failure)Parallel in Non-Atomic: If atomic_load=False, it still runs parallel for performanceThis ensures chunks 6 and 7 never start if chunk 5 fails! ï¿½
